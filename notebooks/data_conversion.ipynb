{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "path_main_dir = \"..\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Facebook Large"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cleora = pd.read_csv(f\"{path_main_dir}/data-source/facebook_large/musae_facebook_edges.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(f\"{path_main_dir}/data/fb-pages/\", exist_ok=True)\n",
    "fb_cleora_input_clique_filename = f\"{path_main_dir}/data/fb-pages/hyperedges-fb-pages.txt\"\n",
    "fb_cleora_input_star_filename = f\"{path_main_dir}/data/fb-pages/star-fb-pages.txt\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(fb_cleora_input_clique_filename, \"w\") as f_cleora_clique, open(fb_cleora_input_star_filename,\n",
    "                                                                         \"w\") as f_cleora_star:\n",
    "    grouped_train = df_cleora.groupby('id_1')\n",
    "    for n, (name, group) in enumerate(grouped_train):\n",
    "        group_list = group['id_2'].tolist()\n",
    "        group_elems = list(map(str, group_list))\n",
    "        f_cleora_clique.write(f\"{name} {' '.join(group_elems)}\\n\")\n",
    "        f_cleora_star.write(f\"{n}\\t{name}\\n\")\n",
    "        for elem in group_elems:\n",
    "            f_cleora_star.write(f\"{n}\\t{elem}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{path_main_dir}/data-source/facebook_large/musae_facebook_target.csv\")\n",
    "df.rename(columns={'page_type': 'target'}, inplace=True)\n",
    "\n",
    "enc = LabelEncoder()\n",
    "df['target'] = enc.fit_transform(df['target'])\n",
    "\n",
    "df.to_csv(f\"{path_main_dir}/data/fb-pages/node-labels-fb-pages.csv\", index=False)\n",
    "\n",
    "with open(f\"{path_main_dir}/data/fb-pages/label-names-fb-pages.txt\", 'w') as f:\n",
    "    for l in enc.classes_:\n",
    "        f.write(l + '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Trivago clicks and Walmart trips"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Copy required files"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_names = ['trivago-clicks', 'walmart-trips']\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    os.makedirs(f\"{path_main_dir}/data/{dataset_name}\", exist_ok=True)\n",
    "\n",
    "    shutil.copy2(f\"{path_main_dir}/data-source/{dataset_name}/label-names-{dataset_name}.txt\",\n",
    "                 f\"{path_main_dir}/data/{dataset_name}/label-names-{dataset_name}.txt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert node labels from txt file to csv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for dataset_name in dataset_names:\n",
    "    filepath_in = f\"{path_main_dir}/data-source/{dataset_name}/node-labels-{dataset_name}.txt\"\n",
    "    filepath_out = f\"{path_main_dir}/data/{dataset_name}/node-labels-{dataset_name}.csv\"\n",
    "\n",
    "    df = pd.read_csv(filepath_in, names=['target'], header=None)\n",
    "    df[\n",
    "        'target'] -= 1  # this is decreasing indexes of labels to make them start from 0, this helps in next step - feature selection\n",
    "    df.to_csv(filepath_out, index=True, index_label='id')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create star format file based on hyperedges file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for dataset_name in dataset_names:\n",
    "    filepath_in = f\"{path_main_dir}/data-source/{dataset_name}/hyperedges-{dataset_name}.txt\"\n",
    "    filepath_out = f\"{path_main_dir}/data/{dataset_name}/star-{dataset_name}.txt\"\n",
    "    filepath_out2 = f\"{path_main_dir}/data/{dataset_name}/hyperedges-{dataset_name}.txt\"\n",
    "\n",
    "    with open(filepath_in, 'r') as f_in, open(filepath_out, 'w') as f_out, open(filepath_out2, 'w') as f_out2:\n",
    "        for i, line in enumerate(f_in.readlines()):\n",
    "            line_list = [int(x) - 1 for x in line.split(',')]\n",
    "            line = str(line_list).replace('[', '').replace(']', '')\n",
    "            line = f\"{i} {line.replace(',', '')}\\n\"\n",
    "            f_out2.write(line)\n",
    "\n",
    "            lst = line[:-1].split(' ')\n",
    "            f_out.write(f\"{lst[0]}\\t{lst[0]}\\n\")\n",
    "            for elem in lst[1:]:\n",
    "                f_out.write(f\"{lst[0]}\\t{elem}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Trivago clicks - continents version"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = f'{path_main_dir}/data/trivago-clicks-continents/'\n",
    "\n",
    "shutil.rmtree(path, ignore_errors=True)\n",
    "shutil.copytree(f\"{path_main_dir}/data/trivago-clicks/\", path, dirs_exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    os.rename(path + filename, path + str(filename[:-4] + \"-continents\" + filename[-4:]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "continents_path = f\"{path_main_dir}/data-source/continents.json\"\n",
    "\n",
    "data = json.load(open(continents_path, 'r'))\n",
    "keys = [x['country'] for x in data]\n",
    "vals = [x['continent'] for x in data]\n",
    "\n",
    "continents = dict(zip(keys, vals))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lines = []\n",
    "\n",
    "with open(f\"{path_main_dir}/data/trivago-clicks-continents/label-names-trivago-clicks-continents.txt\", 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        country = line[:-1]\n",
    "        continent = continents.get(country, \"Other\")\n",
    "        lines.append(continent)\n",
    "\n",
    "with open(f\"{path_main_dir}/data/trivago-clicks-continents/label-names-trivago-clicks-continents.txt\", 'w') as f:\n",
    "    continents_map = dict(zip(set(lines), range(len(lines))))\n",
    "    for key in continents_map:\n",
    "        f.write(key + \"\\n\")\n",
    "\n",
    "    print(continents_map)\n",
    "\n",
    "df = pd.read_csv(f\"{path_main_dir}/data/trivago-clicks-continents/node-labels-trivago-clicks-continents.csv\")\n",
    "\n",
    "for i in range(len(lines)):\n",
    "    index_to_replace = i\n",
    "    replace_value = continents_map[lines[i]]\n",
    "    df['target'].replace(index_to_replace, replace_value, True)\n",
    "\n",
    "df.to_csv(f\"{path_main_dir}/data/trivago-clicks-continents/node-labels-trivago-clicks-continents.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}